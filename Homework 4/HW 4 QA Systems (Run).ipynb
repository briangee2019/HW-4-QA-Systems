{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation: Libraries/Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "#pickle\n",
    "import pickle\n",
    "# regex\n",
    "import re\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import RegexpTokenizer,word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "# sklearn\n",
    "from sklearn.linear_model import LogisticRegression # (setting multi_class=”multinomial”)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# textblob\n",
    "from textblob import TextBlob\n",
    "# itertools\n",
    "import itertools\n",
    "from itertools import islice\n",
    "# spacy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directories!\n",
    "# Start in root of submission folder***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Question Type: \n",
    "Person, Location, Quantity, etc.\n",
    "\n",
    "Steps: \n",
    "* Read all articles into dictionary: {doc_name: content, . . . }\n",
    "* Create labeled training data to train classfier (multi-level response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your question?\n",
      "What is the projected growth of the US economy?\n"
     ]
    }
   ],
   "source": [
    "# Get question input: (string)\n",
    "question = input(\"What is your question?\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = 'Who is the CEO of Google?'\n",
    "#question = 'What percent drop or increase in unemployment is associated with GDP?'\n",
    "#question = 'Which companies went bankrupt in 2014?'\n",
    "#question = 'What affects GDP?'\n",
    "# Keyword heuristic: all cardinal numbers, nouns, adjectives, adverbs\n",
    "keywords = [tuples[0] for tuples in pos_tag(word_tokenize(question))\n",
    "            if tuples[1][0:2] in ['NN','RB','JJ','CD','VB']] # removed VB\n",
    "# drop wh-words and stopwords\n",
    "wh = ['which','what','who','where','when','why']\n",
    "for kw in keywords:\n",
    "    if kw.lower() in wh:\n",
    "        keywords.remove(kw)\n",
    "for kw in keywords:\n",
    "    if kw.lower() in stopwords.words('english'):\n",
    "        keywords.remove(kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify question:\n",
    "# Which companies \n",
    "# What affects GDP? What percentage drop\n",
    "# Who is the CEO of company X? \n",
    "if 'who' in question.lower():\n",
    "    qtype = 'PERSON'\n",
    "if 'which' in question.lower():\n",
    "    qtype = 'ORG'\n",
    "if 'what' in question.lower():\n",
    "    qtype = 'NN'\n",
    "if 'percent' in question.lower() or '%' in question.lower():\n",
    "    qtype = 'PERCENT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Keywords (Query Generation):\n",
    "Entities, Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TextBlob\n",
    "def textblob_tokenizer(str_input):\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    words = [token.stem() for token in tokens]\n",
    "    return words\n",
    "\n",
    "# Use NLTK's PorterStemmer\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# Define take function for random selection\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stem keywords\n",
    "stem_kw = []\n",
    "for i in keywords:\n",
    "    stem_kw += (textblob_tokenizer(i))\n",
    "# compani gives useless info, too common. Remove it, since we already have qtype\n",
    "#if 'compani' in stem_kw:\n",
    "#    stem_kw.remove('compani')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'Saved Objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-e7e51a9a377b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Saved Objects\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Load doc_index_dict from pickle file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdoc_index_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"doc_index_dict.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Load doc_text_dict from pickle file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'Saved Objects'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"Saved Objects\")\n",
    "\n",
    "# Load doc_index_dict from pickle file\n",
    "doc_index_dict = pickle.load(open( \"doc_index_dict.pickle\",\"rb\" ))\n",
    "# Load doc_text_dict from pickle file\n",
    "doc_text_dict = pickle.load( open( \"doc_text_dict.pickle\",\"rb\" ))\n",
    "# Load list of article texts\n",
    "texts = pickle.load( open( \"texts.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Documents for Retrieval\n",
    "Keyword, Document, Subset of Document\n",
    "\n",
    "http://jonathansoma.com/lede/algorithms-2017/classes/more-text-analysis/counting-and-stemming/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tf-idf matrix for documents\n",
    "tfidf_docs = pickle.load( open( \"tfidf_docs.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For words inside of question and their synonyms:\n",
    "K = 10\n",
    "top_docs = list(tfidf_docs[stem_kw].sum(axis=1).nlargest(K).index.values)\n",
    "# Sum up tf-idf scores for docs and return indices of top K documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of top K documents for answer analysis:\n",
    "returned_doc_names = []\n",
    "for doc in top_docs:\n",
    "    returned_doc_names.append(doc_index_dict[doc]) #get all relevant document names (___.txt)\n",
    "\n",
    "returned_docs = {}\n",
    "for filename in returned_doc_names:\n",
    "    returned_docs[filename] = doc_text_dict[filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all sentences from returned documents\n",
    "sentences = []\n",
    "for key,value in returned_docs.items():\n",
    "    sentences += sent_tokenize(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute tf-idf scores for each sentence: treat sentences as documents\n",
    "\n",
    "# Use count vectorizer to get matrix of terms as features and documents as indices for tfidf\n",
    "cvec = CountVectorizer(vocabulary = stem_kw,tokenizer=textblob_tokenizer)\n",
    "matrix = cvec.fit_transform(sentences)\n",
    "cmatrix = pd.DataFrame(matrix.toarray(), columns=cvec.get_feature_names())\n",
    "\n",
    "# Make Tf-idf vectorizer\n",
    "tfidf_vec = TfidfVectorizer(tokenizer = textblob_tokenizer,\n",
    "                      use_idf = False,norm='l2',\n",
    "                      vocabulary = stem_kw) # L - TWO (cosine similarity)\n",
    "\n",
    "# Say hey vectorizer, please read our stuff\n",
    "matrix = tfidf_vec.fit_transform(sentences)\n",
    "\n",
    "# And make a dataframe out of it\n",
    "tfidf_results = pd.DataFrame(matrix.toarray(), columns=tfidf_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute scores for each sentence\n",
    "#start: tfidf_results\n",
    "score = tfidf_results\n",
    "score['Sentence Keywords'] = 0\n",
    "\n",
    "# Create vector to put into scoring dataframe\n",
    "words_list = score['Sentence Keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)-1):\n",
    "    # for each sentence\n",
    "    words = [tuples[0] for tuples in pos_tag(word_tokenize(sentences[i]))\n",
    "             if tuples[1][0:2] in ['NN','RB','JJ']] #remove VB\n",
    "    for word in words:\n",
    "        if word.lower() in stopwords.words('english'):\n",
    "            words.remove(word)\n",
    "    # stem words\n",
    "    stem_words = []\n",
    "    for word in words:\n",
    "        stem_words += textblob_tokenizer(word)\n",
    "    # assign stemmed sentence back into matrix\n",
    "    words_list[i] = stem_words\n",
    "\n",
    "score['Sentence Keywords'] = words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate scores:\n",
    "#1. Check for bigram matches +2 if matched (bigrams matching any pairs of words in question)\n",
    "score['Score'] = 0\n",
    "\n",
    "# Get question bigrams\n",
    "def find_bigrams(input_list):\n",
    "    bigram_list = []\n",
    "    for i in range(len(input_list)-1):\n",
    "        bigram_list.append((input_list[i], input_list[i+1]))\n",
    "    return bigram_list\n",
    "q_bigrams = find_bigrams(stem_kw)\n",
    "\n",
    "# Turn score['Sentence Keywords'] into list of lists\n",
    "sent_kw = score['Sentence Keywords'].tolist()\n",
    "score_list = score['Score'].tolist()\n",
    "\n",
    "#2. Scoring sentences\n",
    "for i in range(0,len(score['Sentence Keywords'])-1):\n",
    "    #for pair in [pairs for pairs in itertools.product(stem_kw, repeat=2)]: #all pairs of q_kws\n",
    "        #if pair in find_bigrams(sent_kw[i]):\n",
    "    if q_bigrams in find_bigrams(sent_kw[i]):\n",
    "        score_list[i] += 2 \n",
    "    for kw in stem_kw:\n",
    "        if kw in sent_kw[i]:\n",
    "            score_list[i] += score[kw].loc[i] #add tfidf score if in sentence\n",
    "        #if kw not in sent_kw[i]:\n",
    "         #   score_list[i] -= tfidf_docs[kw].sum() #subtract tfidf score if word not contained\n",
    "            \n",
    "score['Sentence Keywords'] = sent_kw\n",
    "score['Score'] = score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final answer scores:\n",
    "# Sum up tf-idf scores for docs and return indices of top K documents\n",
    "K = 10\n",
    "top_sents = list(score['Score'].nlargest(K).index.values)\n",
    "\n",
    "# Return top sentences as answer\n",
    "answer_sents = [sentences[i] for i in top_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Retrieved Documents with Type:\n",
    "Person, Location, Quantity, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use nlp to tag entities in the answer sentences\n",
    "#print([(X.text, X.label_) for X in answer.ents])\n",
    "\n",
    "clean_sent_list = []\n",
    "dumb_words = ['i','we','you','your','these','eyes','our']\n",
    "\n",
    "# Remove stopwords in answer sentences -> output is list of list of words\n",
    "for i in range(len(answer_sents)-1):\n",
    "    clean_sent_list.append(word_tokenize(answer_sents[i]))\n",
    "    for word in clean_sent_list[i]:\n",
    "        if word.lower() in stopwords.words('english') or word.lower() in dumb_words:\n",
    "            clean_sent_list[i].remove(word)\n",
    "            \n",
    " # Stitch back together sentences from lists\n",
    "for lists in clean_sent_list:\n",
    "    i = 0\n",
    "    sentence = ''\n",
    "    for word in lists:\n",
    "        sentence += word + ' '\n",
    "    answer_sents[i] = sentence\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of ceos and companies and pickle them\n",
    "ceos = pickle.load(open( \"ceos_list.pickle\",\"rb\" ))\n",
    "comps = pickle.load(open(\"comps_list.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even South Africa\n",
      "Even South Africa , Credit Suisse dubbed most troubled emerging market economy a year ago , see currency stabilize , fewer labor strikes , higher industrial output , a doubling GDP growth 1.2 percent 2.4 percent .  \n",
      "\n",
      "Credit Suisse\n",
      "Even South Africa , Credit Suisse dubbed most troubled emerging market economy a year ago , see currency stabilize , fewer labor strikes , higher industrial output , a doubling GDP growth 1.2 percent 2.4 percent .  \n",
      "\n",
      "most troubled emerging market economy\n",
      "Even South Africa , Credit Suisse dubbed most troubled emerging market economy a year ago , see currency stabilize , fewer labor strikes , higher industrial output , a doubling GDP growth 1.2 percent 2.4 percent .  \n",
      "\n",
      "currency\n",
      "Even South Africa , Credit Suisse dubbed most troubled emerging market economy a year ago , see currency stabilize , fewer labor strikes , higher industrial output , a doubling GDP growth 1.2 percent 2.4 percent .  \n",
      "\n",
      "We\n",
      "\"We expect that commodity price volatility could temper loan growth in local economies with significant exposure to the oil industry, but that on the whole the risks posed to large U.S. banks are not material.\" \n",
      "\n",
      "commodity price volatility\n",
      "\"We expect that commodity price volatility could temper loan growth in local economies with significant exposure to the oil industry, but that on the whole the risks posed to large U.S. banks are not material.\" \n",
      "\n",
      "local economies\n",
      "\"We expect that commodity price volatility could temper loan growth in local economies with significant exposure to the oil industry, but that on the whole the risks posed to large U.S. banks are not material.\" \n",
      "\n",
      "significant exposure\n",
      "\"We expect that commodity price volatility could temper loan growth in local economies with significant exposure to the oil industry, but that on the whole the risks posed to large U.S. banks are not material.\" \n",
      "\n",
      "the oil industry\n",
      "\"We expect that commodity price volatility could temper loan growth in local economies with significant exposure to the oil industry, but that on the whole the risks posed to large U.S. banks are not material.\" \n",
      "\n",
      "the risks\n",
      "\"We expect that commodity price volatility could temper loan growth in local economies with significant exposure to the oil industry, but that on the whole the risks posed to large U.S. banks are not material.\" \n",
      "\n",
      "large U.S. banks\n",
      "\"We expect that commodity price volatility could temper loan growth in local economies with significant exposure to the oil industry, but that on the whole the risks posed to large U.S. banks are not material.\" \n",
      "\n",
      "We\n",
      "\"We believe banks in general should benefit from lower oil prices driven by increasing loan growth and rising interest rates from an accelerating economy,\" said Cassidy. \n",
      "\n",
      "banks\n",
      "\"We believe banks in general should benefit from lower oil prices driven by increasing loan growth and rising interest rates from an accelerating economy,\" said Cassidy. \n",
      "\n",
      "lower oil prices\n",
      "\"We believe banks in general should benefit from lower oil prices driven by increasing loan growth and rising interest rates from an accelerating economy,\" said Cassidy. \n",
      "\n",
      "increasing loan growth\n",
      "\"We believe banks in general should benefit from lower oil prices driven by increasing loan growth and rising interest rates from an accelerating economy,\" said Cassidy. \n",
      "\n",
      "rising interest rates\n",
      "\"We believe banks in general should benefit from lower oil prices driven by increasing loan growth and rising interest rates from an accelerating economy,\" said Cassidy. \n",
      "\n",
      "an accelerating economy\n",
      "\"We believe banks in general should benefit from lower oil prices driven by increasing loan growth and rising interest rates from an accelerating economy,\" said Cassidy. \n",
      "\n",
      "Cassidy\n",
      "\"We believe banks in general should benefit from lower oil prices driven by increasing loan growth and rising interest rates from an accelerating economy,\" said Cassidy. \n",
      "\n",
      "Our contacts\n",
      "Our contacts are fairly optimistic and expect moderate to strong growth in 2015, though some expressed concern about the strengthening dollar and weakening foreign economies. \n",
      "\n",
      "strong growth\n",
      "Our contacts are fairly optimistic and expect moderate to strong growth in 2015, though some expressed concern about the strengthening dollar and weakening foreign economies. \n",
      "\n",
      "concern\n",
      "Our contacts are fairly optimistic and expect moderate to strong growth in 2015, though some expressed concern about the strengthening dollar and weakening foreign economies. \n",
      "\n",
      "the strengthening dollar\n",
      "Our contacts are fairly optimistic and expect moderate to strong growth in 2015, though some expressed concern about the strengthening dollar and weakening foreign economies. \n",
      "\n",
      "foreign economies\n",
      "Our contacts are fairly optimistic and expect moderate to strong growth in 2015, though some expressed concern about the strengthening dollar and weakening foreign economies. \n",
      "\n",
      "the downside\n",
      "On the downside, we heard a few reports about private capital being readily available so construction could proceed, but owners are reluctant to move projects into the construction phase because of uncertainty about the economy. \n",
      "\n",
      "we\n",
      "On the downside, we heard a few reports about private capital being readily available so construction could proceed, but owners are reluctant to move projects into the construction phase because of uncertainty about the economy. \n",
      "\n",
      "a few reports\n",
      "On the downside, we heard a few reports about private capital being readily available so construction could proceed, but owners are reluctant to move projects into the construction phase because of uncertainty about the economy. \n",
      "\n",
      "private capital\n",
      "On the downside, we heard a few reports about private capital being readily available so construction could proceed, but owners are reluctant to move projects into the construction phase because of uncertainty about the economy. \n",
      "\n",
      "construction\n",
      "On the downside, we heard a few reports about private capital being readily available so construction could proceed, but owners are reluctant to move projects into the construction phase because of uncertainty about the economy. \n",
      "\n",
      "owners\n",
      "On the downside, we heard a few reports about private capital being readily available so construction could proceed, but owners are reluctant to move projects into the construction phase because of uncertainty about the economy. \n",
      "\n",
      "projects\n",
      "On the downside, we heard a few reports about private capital being readily available so construction could proceed, but owners are reluctant to move projects into the construction phase because of uncertainty about the economy. \n",
      "\n",
      "the construction phase\n",
      "On the downside, we heard a few reports about private capital being readily available so construction could proceed, but owners are reluctant to move projects into the construction phase because of uncertainty about the economy. \n",
      "\n",
      "uncertainty\n",
      "On the downside, we heard a few reports about private capital being readily available so construction could proceed, but owners are reluctant to move projects into the construction phase because of uncertainty about the economy. \n",
      "\n",
      "the economy\n",
      "On the downside, we heard a few reports about private capital being readily available so construction could proceed, but owners are reluctant to move projects into the construction phase because of uncertainty about the economy. \n",
      "\n",
      "Builders\n",
      "Builders expected that an improving economy and continued low interest rates would help support steady growth in new construction. \n",
      "\n",
      "an improving economy\n",
      "Builders expected that an improving economy and continued low interest rates would help support steady growth in new construction. \n",
      "\n",
      "continued low interest rates\n",
      "Builders expected that an improving economy and continued low interest rates would help support steady growth in new construction. \n",
      "\n",
      "steady growth\n",
      "Builders expected that an improving economy and continued low interest rates would help support steady growth in new construction. \n",
      "\n",
      "new construction\n",
      "Builders expected that an improving economy and continued low interest rates would help support steady growth in new construction. \n",
      "\n",
      "the combination\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Given the combination of improving economic conditions and rebounding earnings growth, we believe 2015 will represent another year of solid gains for US stocks,\" Belski wrote in a December 1 note to clients. \n",
      "\n",
      "economic conditions\n",
      "\"Given the combination of improving economic conditions and rebounding earnings growth, we believe 2015 will represent another year of solid gains for US stocks,\" Belski wrote in a December 1 note to clients. \n",
      "\n",
      "earnings growth\n",
      "\"Given the combination of improving economic conditions and rebounding earnings growth, we believe 2015 will represent another year of solid gains for US stocks,\" Belski wrote in a December 1 note to clients. \n",
      "\n",
      "we\n",
      "\"Given the combination of improving economic conditions and rebounding earnings growth, we believe 2015 will represent another year of solid gains for US stocks,\" Belski wrote in a December 1 note to clients. \n",
      "\n",
      "another year\n",
      "\"Given the combination of improving economic conditions and rebounding earnings growth, we believe 2015 will represent another year of solid gains for US stocks,\" Belski wrote in a December 1 note to clients. \n",
      "\n",
      "solid gains\n",
      "\"Given the combination of improving economic conditions and rebounding earnings growth, we believe 2015 will represent another year of solid gains for US stocks,\" Belski wrote in a December 1 note to clients. \n",
      "\n",
      "US stocks\n",
      "\"Given the combination of improving economic conditions and rebounding earnings growth, we believe 2015 will represent another year of solid gains for US stocks,\" Belski wrote in a December 1 note to clients. \n",
      "\n",
      "Belski\n",
      "\"Given the combination of improving economic conditions and rebounding earnings growth, we believe 2015 will represent another year of solid gains for US stocks,\" Belski wrote in a December 1 note to clients. \n",
      "\n",
      "a December 1 note\n",
      "\"Given the combination of improving economic conditions and rebounding earnings growth, we believe 2015 will represent another year of solid gains for US stocks,\" Belski wrote in a December 1 note to clients. \n",
      "\n",
      "clients\n",
      "\"Given the combination of improving economic conditions and rebounding earnings growth, we believe 2015 will represent another year of solid gains for US stocks,\" Belski wrote in a December 1 note to clients. \n",
      "\n",
      "Credit Suisse\n",
      "Overall, Credit Suisse expects the growth of emerging market economies to rise a mere 0.2 percentage points to 4.6 percent in 2015. \n",
      "\n",
      "the growth\n",
      "Overall, Credit Suisse expects the growth of emerging market economies to rise a mere 0.2 percentage points to 4.6 percent in 2015. \n",
      "\n",
      "emerging market economies\n",
      "Overall, Credit Suisse expects the growth of emerging market economies to rise a mere 0.2 percentage points to 4.6 percent in 2015. \n",
      "\n",
      "a mere 0.2 percentage points\n",
      "Overall, Credit Suisse expects the growth of emerging market economies to rise a mere 0.2 percentage points to 4.6 percent in 2015. \n",
      "\n",
      "4.6 percent\n",
      "Overall, Credit Suisse expects the growth of emerging market economies to rise a mere 0.2 percentage points to 4.6 percent in 2015. \n",
      "\n",
      "Even South Africa\n",
      "Even South Africa, which Credit Suisse dubbed the most troubled emerging market economy just a year ago, should see its currency stabilize, fewer labor strikes, higher industrial output, and a doubling of GDP growth from 1.2 percent to 2.4 percent. \n",
      "\n",
      "Credit Suisse\n",
      "Even South Africa, which Credit Suisse dubbed the most troubled emerging market economy just a year ago, should see its currency stabilize, fewer labor strikes, higher industrial output, and a doubling of GDP growth from 1.2 percent to 2.4 percent. \n",
      "\n",
      "its currency\n",
      "Even South Africa, which Credit Suisse dubbed the most troubled emerging market economy just a year ago, should see its currency stabilize, fewer labor strikes, higher industrial output, and a doubling of GDP growth from 1.2 percent to 2.4 percent. \n",
      "\n",
      "GDP growth\n",
      "Even South Africa, which Credit Suisse dubbed the most troubled emerging market economy just a year ago, should see its currency stabilize, fewer labor strikes, higher industrial output, and a doubling of GDP growth from 1.2 percent to 2.4 percent. \n",
      "\n",
      "1.2 percent\n",
      "Even South Africa, which Credit Suisse dubbed the most troubled emerging market economy just a year ago, should see its currency stabilize, fewer labor strikes, higher industrial output, and a doubling of GDP growth from 1.2 percent to 2.4 percent. \n",
      "\n",
      "2.4 percent\n",
      "Even South Africa, which Credit Suisse dubbed the most troubled emerging market economy just a year ago, should see its currency stabilize, fewer labor strikes, higher industrial output, and a doubling of GDP growth from 1.2 percent to 2.4 percent. \n",
      "\n",
      "This conservative strategy\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n",
      "Germany\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n",
      "quantitative easing\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n",
      "Germany's growth\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n",
      "unemployment\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n",
      "a record low\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n",
      "it\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n",
      "more troubled economies\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n",
      "places\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n",
      "Spain\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n",
      "Italy\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n",
      "Greece\n",
      "This conservative strategy may work for Germany — which does not necessarily need quantitative easing (Germany's growth is slow, but unemployment is at a record low) — but it does not bode well for more troubled economies in places like Spain, Italy, and Greece. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Match answer type to question type and print answers\n",
    "for answers in answer_sents:    \n",
    "    if qtype == \"NN\":\n",
    "        for chunk in nlp(answers).noun_chunks:\n",
    "            print(chunk.text)\n",
    "            print(answers, '\\n')\n",
    "    else:\n",
    "        for ent in nlp(answers).ents:\n",
    "            if ent.label_ == qtype:\n",
    "                if qtype == 'PERSON':\n",
    "                    if str(ent) in ceos:\n",
    "                        print(ent)\n",
    "                        print(answers,'\\n')\n",
    "                #elif qtype == 'ORG':\n",
    "                 #   if str(ent) in comps:\n",
    "                  #      print(ent)\n",
    "                   #     print(answers,'\\n')\n",
    "                else: \n",
    "                    print(ent)\n",
    "                    print(answers,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
